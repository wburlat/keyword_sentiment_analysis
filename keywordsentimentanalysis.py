# -*- coding: utf-8 -*-
"""keywordsentimentanalysis.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1_0PDDMRCHyhW29vHd8X72ZHVCJRBopI1

BlogMe Sentiment and Keyword Analysis By Wendel Burlat
"""

import pandas as pd

!pip install nltk

import nltk
from nltk.sentiment.vader import SentimentIntensityAnalyzer

from google.colab import files
uploades = files.upload()

data= pd.read_excel('articles.xlsx')

# Print the first few rows of the dataset
data.head()

# Print information about the dataset
data.info()

# Print descriptive statistics of the dataset
data.describe()

# Count the number of articles per source
data.groupby(['source_id'])['article_id'].count()

# Count the number of reactions per publisher
data.groupby(['source_id'])['engagement_reaction_count'].sum()

# Remove the 'engagement_comment_plugin_count' column
data= data.drop('engagement_comment_plugin_count',axis =1)

# Define a function to flag articles containing a certain keyword
def keywordflag(keyword):
  keyword_flag=[]
  length = len(data)
  for x in range(0,length):
      heading = data['title'][x]
      try:
        if keyword in heading:
         flag= 1
        else:
         flag=0
      except:
         flag=0
      keyword_flag.append(flag)
  return keyword_flag

# Flag articles containing the word 'murder'
keywordflag= keywordflag('murder')
print(keywordflag)

# Add the keyword flag as a new column to the dataset
data['keyword_flag'] = pd.Series(keywordflag)

# Download the VADER lexicon for sentiment analysis
nltk.download("vader_lexicon")

# Instantiate the SentimentIntensityAnalyzer class
sent_analyzer = SentimentIntensityAnalyzer()

# Test the analyzer on a single article title
text = data['title'][16]
sent = sent_analyzer.polarity_scores(text)
print(sent)

# Analyze the sentiment of all article titles
title_neg_sentiment = []
title_pos_sentiment = []
title_neu_sentiment = []

length = len(data)
for x in range(0,length):
  try:
    text = data['title'][x]
    sent_analyzer = SentimentIntensityAnalyzer()
    sent = sent_analyzer.polarity_scores(text)
    neg = sent['neg']
    pos = sent['pos']
    neu = sent['neu']
  except:
    neg = 0
    pos = 0
    neu = 0
  title_neg_sentiment.append(neg)
  title_pos_sentiment.append(pos)
  title_neu_sentiment.append(neu)

# Add the sentiment scores as new columns to the dataset
title_neg_sentiment = pd.Series( title_neg_sentiment)
title_pos_sentiment = pd.Series( title_pos_sentiment)
title_neu_sentiment = pd.Series( title_neu_sentiment)

data['title_neg_sentiment']=title_neg_sentiment
data['title_pos_sentiment']=title_pos_sentiment
data['title_neu_sentiment']=title_neu_sentiment

data.head()

# Save the cleaned dataset to an Excel file
data.to_excel('blog_cleaned.xlsx', sheet_name = 'blogmedata', index=False)